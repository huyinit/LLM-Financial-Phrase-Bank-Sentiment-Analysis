{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3f54a6",
   "metadata": {
    "papermill": {
     "duration": 0.010876,
     "end_time": "2024-06-20T21:25:16.435773",
     "exception": false,
     "start_time": "2024-06-20T21:25:16.424897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fine-tune Llama 3 for Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e5646",
   "metadata": {
    "papermill": {
     "duration": 0.011015,
     "end_time": "2024-06-20T21:25:16.497909",
     "exception": false,
     "start_time": "2024-06-20T21:25:16.486894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e4d9fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:25:16.520382Z",
     "iopub.status.busy": "2024-06-20T21:25:16.519824Z",
     "iopub.status.idle": "2024-06-20T21:27:29.808274Z",
     "shell.execute_reply": "2024-06-20T21:27:29.807291Z"
    },
    "papermill": {
     "duration": 133.302294,
     "end_time": "2024-06-20T21:27:29.810711",
     "exception": false,
     "start_time": "2024-06-20T21:25:16.508417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n",
    "# !pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
    "# !pip install -q -U transformers==\"4.40.0\"\n",
    "# !pip install -q -U accelerate\n",
    "# !pip install -q -U datasets\n",
    "# !pip install -q -U trl\n",
    "# !pip install -q -U peft\n",
    "# !pip install -q -U tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3be251ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d861896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:29.855163Z",
     "iopub.status.busy": "2024-06-20T21:27:29.854854Z",
     "iopub.status.idle": "2024-06-20T21:27:29.859361Z",
     "shell.execute_reply": "2024-06-20T21:27:29.858514Z"
    },
    "papermill": {
     "duration": 0.018282,
     "end_time": "2024-06-20T21:27:29.861276",
     "exception": false,
     "start_time": "2024-06-20T21:27:29.842994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11dca30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:29.904828Z",
     "iopub.status.busy": "2024-06-20T21:27:29.904312Z",
     "iopub.status.idle": "2024-06-20T21:27:29.908161Z",
     "shell.execute_reply": "2024-06-20T21:27:29.907295Z"
    },
    "papermill": {
     "duration": 0.017308,
     "end_time": "2024-06-20T21:27:29.910006",
     "exception": false,
     "start_time": "2024-06-20T21:27:29.892698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def990a",
   "metadata": {
    "papermill": {
     "duration": 0.010338,
     "end_time": "2024-06-20T21:27:29.930802",
     "exception": false,
     "start_time": "2024-06-20T21:27:29.920464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the following cell there are all the other imports for running the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fbb06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:29.952830Z",
     "iopub.status.busy": "2024-06-20T21:27:29.952537Z",
     "iopub.status.idle": "2024-06-20T21:27:48.655310Z",
     "shell.execute_reply": "2024-06-20T21:27:48.654351Z"
    },
    "papermill": {
     "duration": 18.716333,
     "end_time": "2024-06-20T21:27:48.657670",
     "exception": false,
     "start_time": "2024-06-20T21:27:29.941337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected accelerate version: 0.34.2\n",
      "Detected bitsandbytes version: 0.44.1\n",
      "Detected datasets version: 3.0.1\n",
      "Detected jinja2 version: 2.11.3\n",
      "Detected nltk version: 3.7\n",
      "Detected pandas version: 1.4.2\n",
      "Detected peft version: 0.13.0\n",
      "Detected psutil version: 5.8.0\n",
      "Detected pytest version: 7.1.1\n",
      "Detected safetensors version: 0.4.5\n",
      "Detected scipy version: 1.7.3\n",
      "Detected tokenizers version: 0.19.1\n",
      "Detected torchvision version: 0.15.2+cu117\n",
      "Detected torch version: 2.1.2+cu118\n",
      "Detected PIL version 9.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_default_log_level: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected rich version: 13.9.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to import libraries: 3.05 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Bắt đầu tính thời gian\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Kết thúc tính thời gian\n",
    "end_time = time.time()\n",
    "print(f\"Time to import libraries: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9790589f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:48.681518Z",
     "iopub.status.busy": "2024-06-20T21:27:48.680853Z",
     "iopub.status.idle": "2024-06-20T21:27:48.685728Z",
     "shell.execute_reply": "2024-06-20T21:27:48.684866Z"
    },
    "papermill": {
     "duration": 0.018746,
     "end_time": "2024-06-20T21:27:48.687953",
     "exception": false,
     "start_time": "2024-06-20T21:27:48.669207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version 2.1.2+cu118\n",
      "working on cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"pytorch version {torch.__version__}\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"working on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d07b47",
   "metadata": {
    "papermill": {
     "duration": 0.010421,
     "end_time": "2024-06-20T21:27:48.738326",
     "exception": false,
     "start_time": "2024-06-20T21:27:48.727905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Disabling two features in PyTorch related to memory efficiency and speed during operations on the Graphics Processing Unit (GPU) specifically for the scaled dot product attention (SDPA) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "206a96eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:48.760963Z",
     "iopub.status.busy": "2024-06-20T21:27:48.760697Z",
     "iopub.status.idle": "2024-06-20T21:27:48.764508Z",
     "shell.execute_reply": "2024-06-20T21:27:48.763751Z"
    },
    "papermill": {
     "duration": 0.017241,
     "end_time": "2024-06-20T21:27:48.766411",
     "exception": false,
     "start_time": "2024-06-20T21:27:48.749170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a43dfa",
   "metadata": {
    "papermill": {
     "duration": 0.010576,
     "end_time": "2024-06-20T21:27:48.787897",
     "exception": false,
     "start_time": "2024-06-20T21:27:48.777321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing the data and the core evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceca451c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:48.831979Z",
     "iopub.status.busy": "2024-06-20T21:27:48.831740Z",
     "iopub.status.idle": "2024-06-20T21:27:50.245342Z",
     "shell.execute_reply": "2024-06-20T21:27:50.244625Z"
    },
    "papermill": {
     "duration": 1.427479,
     "end_time": "2024-06-20T21:27:50.247666",
     "exception": false,
     "start_time": "2024-06-20T21:27:48.820187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to read data: 0.01 seconds\n",
      "Số lượng nhãn trong tập huấn luyện:\n",
      "neutral     1728\n",
      "positive     818\n",
      "negative     363\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Số lượng nhãn trong tập đánh giá:\n",
      "neutral     575\n",
      "positive    272\n",
      "negative    120\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Số lượng nhãn trong tập kiểm tra:\n",
      "neutral     576\n",
      "positive    273\n",
      "negative    121\n",
      "Name: sentiment, dtype: int64\n",
      "Time to create prompts: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "filename = \"all-data.csv\"\n",
    "\n",
    "# Bắt đầu tính thời gian cho việc đọc dữ liệu\n",
    "start_time_read = time.time()\n",
    "\n",
    "df = pd.read_csv(filename, \n",
    "                 names=[\"sentiment\", \"text\"],\n",
    "                 encoding=\"utf-8\", encoding_errors=\"replace\")\n",
    "\n",
    "end_time_read = time.time()\n",
    "print(f\"Time to read data: {end_time_read - start_time_read:.2f} seconds\")\n",
    "\n",
    "# X_train = list()\n",
    "# X_test = list()\n",
    "\n",
    "# # Bắt đầu tính thời gian cho việc chia tập dữ liệu\n",
    "# start_time_split = time.time()\n",
    "\n",
    "# for sentiment in [\"positive\", \"neutral\", \"negative\"]:\n",
    "#     train, test  = train_test_split(df[df.sentiment == sentiment], \n",
    "#                                     train_size=300,\n",
    "#                                     test_size=300, \n",
    "#                                     random_state=42)\n",
    "#     X_train.append(train)\n",
    "#     X_test.append(test)\n",
    "\n",
    "# X_train = pd.concat(X_train).sample(frac=1, random_state=10)\n",
    "# X_test = pd.concat(X_test)\n",
    "\n",
    "# # Kết thúc thời gian chia tập dữ liệu\n",
    "# end_time_split = time.time()\n",
    "# print(f\"Time to split data: {end_time_split - start_time_split:.2f} seconds\")\n",
    "\n",
    "# eval_idx = [idx for idx in df.index if idx not in list(X_train.index) + list(X_test.index)]\n",
    "# X_eval = df[df.index.isin(eval_idx)]\n",
    "# X_eval = (X_eval\n",
    "#           .groupby('sentiment', group_keys=False)\n",
    "#           .apply(lambda x: x.sample(n=50, random_state=10, replace=True)))\n",
    "# X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "X_train = list()\n",
    "X_test = list()\n",
    "X_eval = list()\n",
    "\n",
    "# Bắt đầu tính thời gian cho việc chia tập dữ liệu\n",
    "start_time_split = time.time()\n",
    "\n",
    "for sentiment in [\"positive\", \"neutral\", \"negative\"]:\n",
    "    # Chia dữ liệu thành tập huấn luyện và tập còn lại (test + eval)\n",
    "    train_val, test = train_test_split(df[df.sentiment == sentiment], \n",
    "                                       train_size=0.8,  # 80% cho train và eval\n",
    "                                       random_state=42)\n",
    "    \n",
    "    # Chia tập còn lại thành test và eval\n",
    "    eval_size = int(len(train_val) * 0.25)  # 20% của 80% là 20% tổng thể\n",
    "    train, eval = train_test_split(train_val, \n",
    "                                   test_size=eval_size, \n",
    "                                   random_state=42)\n",
    "    \n",
    "    # Thêm vào các danh sách\n",
    "    X_train.append(train)\n",
    "    X_eval.append(eval)\n",
    "    X_test.append(test)\n",
    "\n",
    "# Kết hợp các tập lại\n",
    "X_train = pd.concat(X_train).sample(frac=1, random_state=10).reset_index(drop=True)\n",
    "X_eval = pd.concat(X_eval).reset_index(drop=True)\n",
    "X_test = pd.concat(X_test).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Thống kê số lượng nhãn cho từng tập\n",
    "train_label_counts = X_train['sentiment'].value_counts()\n",
    "eval_label_counts = X_eval['sentiment'].value_counts()\n",
    "test_label_counts = X_test['sentiment'].value_counts()\n",
    "\n",
    "# In ra kết quả thống kê\n",
    "print(\"Số lượng nhãn trong tập huấn luyện:\")\n",
    "print(train_label_counts)\n",
    "print(\"\\nSố lượng nhãn trong tập đánh giá:\")\n",
    "print(eval_label_counts)\n",
    "print(\"\\nSố lượng nhãn trong tập kiểm tra:\")\n",
    "print(test_label_counts)\n",
    "\n",
    "# Bắt đầu tính thời gian cho việc tạo prompt\n",
    "start_time_prompt = time.time()\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"text\"]}] = \"\"\".strip()\n",
    "\n",
    "X_train = pd.DataFrame(X_train.apply(generate_prompt, axis=1), \n",
    "                       columns=[\"text\"])\n",
    "X_eval = pd.DataFrame(X_eval.apply(generate_prompt, axis=1), \n",
    "                      columns=[\"text\"])\n",
    "\n",
    "y_true = X_test.sentiment\n",
    "X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n",
    "\n",
    "# Kết thúc thời gian tạo prompt\n",
    "end_time_prompt = time.time()\n",
    "print(f\"Time to create prompts: {end_time_prompt - start_time_prompt:.2f} seconds\")\n",
    "\n",
    "train_data = Dataset.from_pandas(X_train)\n",
    "eval_data = Dataset.from_pandas(X_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e789580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Values ---\n",
      "Total records in df: 4846\n",
      "Total records in X_train: 2909\n",
      "Total records in X_eval: 967\n",
      "Total records in X_test: 970\n",
      "Total records in y_true: 970\n",
      "\n",
      "y_true distribution:\n",
      "neutral     576\n",
      "positive    273\n",
      "negative    121\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Train dataset:\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2909\n",
      "})\n",
      "\n",
      "Eval dataset:\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 967\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In ra giá trị của từng biến và tổng số lượng bản ghi\n",
    "print(\"\\n--- Final Values ---\")\n",
    "print(f\"Total records in df: {df.shape[0]}\")\n",
    "print(f\"Total records in X_train: {X_train.shape[0]}\")\n",
    "print(f\"Total records in X_eval: {X_eval.shape[0]}\")\n",
    "print(f\"Total records in X_test: {X_test.shape[0]}\")\n",
    "print(f\"Total records in y_true: {len(y_true)}\")\n",
    "print(\"\\ny_true distribution:\")\n",
    "print(y_true.value_counts())  # Hiển thị số lượng từng nhãn trong y_true\n",
    "print(\"\\nTrain dataset:\")\n",
    "print(train_data)\n",
    "print(\"\\nEval dataset:\")\n",
    "print(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dca745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Values ---\n",
      "X_train:\n",
      "                                                text\n",
      "0  Analyze the sentiment of the news headline enc...\n",
      "1  Analyze the sentiment of the news headline enc...\n",
      "2  Analyze the sentiment of the news headline enc...\n",
      "3  Analyze the sentiment of the news headline enc...\n",
      "4  Analyze the sentiment of the news headline enc...\n",
      "\n",
      "X_eval:\n",
      "                                                text\n",
      "0  Analyze the sentiment of the news headline enc...\n",
      "1  Analyze the sentiment of the news headline enc...\n",
      "2  Analyze the sentiment of the news headline enc...\n",
      "3  Analyze the sentiment of the news headline enc...\n",
      "4  Analyze the sentiment of the news headline enc...\n",
      "\n",
      "X_test:\n",
      "                                                text\n",
      "0  Analyze the sentiment of the news headline enc...\n",
      "1  Analyze the sentiment of the news headline enc...\n",
      "2  Analyze the sentiment of the news headline enc...\n",
      "3  Analyze the sentiment of the news headline enc...\n",
      "4  Analyze the sentiment of the news headline enc...\n",
      "\n",
      "y_true:\n",
      "neutral     576\n",
      "positive    273\n",
      "negative    121\n",
      "Name: sentiment, dtype: int64\n",
      "\n",
      "Train dataset:\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 2909\n",
      "})\n",
      "\n",
      "Eval dataset:\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 967\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In ra giá trị của từng biến\n",
    "print(\"\\n--- Final Values ---\")\n",
    "print(\"X_train:\")\n",
    "print(X_train.head())  # Hiển thị 5 hàng đầu tiên của X_train\n",
    "print(\"\\nX_eval:\")\n",
    "print(X_eval.head())   # Hiển thị 5 hàng đầu tiên của X_eval\n",
    "print(\"\\nX_test:\")\n",
    "print(X_test.head())   # Hiển thị 5 hàng đầu tiên của X_test\n",
    "print(\"\\ny_true:\")\n",
    "print(y_true.value_counts())  # Hiển thị số lượng từng nhãn trong y_true\n",
    "print(\"\\nTrain dataset:\")\n",
    "print(train_data)\n",
    "print(\"\\nEval dataset:\")\n",
    "print(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c561132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Analyze the sentiment of the news headline enclosed in square brackets, \\n            determine if it is positive, neutral, or negative, and return the answer as \\n            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\\n\\n            [The contractor of the shopping center , China State Construction Engineering Corporation , has previously built e.g. airports , hotels and factories for large international customers in different parts of the world .] = neutral'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "731cb86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:50.292980Z",
     "iopub.status.busy": "2024-06-20T21:27:50.292462Z",
     "iopub.status.idle": "2024-06-20T21:27:50.301244Z",
     "shell.execute_reply": "2024-06-20T21:27:50.300457Z"
    },
    "papermill": {
     "duration": 0.022201,
     "end_time": "2024-06-20T21:27:50.303097",
     "exception": false,
     "start_time": "2024-06-20T21:27:50.280896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    labels = ['positive', 'neutral', 'negative']\n",
    "    mapping = {'positive': 2, 'neutral': 1, 'none':1, 'negative': 0}\n",
    "    def map_func(x):\n",
    "        return mapping.get(x, 1)\n",
    "    \n",
    "    y_true = np.vectorize(map_func)(y_true)\n",
    "    y_pred = np.vectorize(map_func)(y_pred)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    # Generate accuracy report\n",
    "    unique_labels = set(y_true)  # Get unique labels\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        label_indices = [i for i in range(len(y_true)) \n",
    "                         if y_true[i] == label]\n",
    "        label_y_true = [y_true[i] for i in label_indices]\n",
    "        label_y_pred = [y_pred[i] for i in label_indices]\n",
    "        accuracy = accuracy_score(label_y_true, label_y_pred)\n",
    "        print(f'Accuracy for label {label}: {accuracy:.3f}')\n",
    "        \n",
    "    # Generate classification report\n",
    "    class_report = classification_report(y_true=y_true, y_pred=y_pred)\n",
    "    print('\\nClassification Report:')\n",
    "    print(class_report)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=[0, 1, 2])\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe3f54",
   "metadata": {
    "papermill": {
     "duration": 0.010322,
     "end_time": "2024-06-20T21:27:50.324139",
     "exception": false,
     "start_time": "2024-06-20T21:27:50.313817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing the model without fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bf7d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Khôi phục trạng thái cảnh báo về mặc định\n",
    "warnings.resetwarnings()\n",
    "\n",
    "# Nếu bạn đã từng dùng filterwarnings, không cần thiết phải xóa nó,\n",
    "# nhưng nếu có, bạn có thể xóa hoặc bình luận dòng này.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "044b5096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:50.368804Z",
     "iopub.status.busy": "2024-06-20T21:27:50.368264Z",
     "iopub.status.idle": "2024-06-20T21:29:38.348692Z",
     "shell.execute_reply": "2024-06-20T21:29:38.347700Z"
    },
    "papermill": {
     "duration": 107.994237,
     "end_time": "2024-06-20T21:29:38.350874",
     "exception": false,
     "start_time": "2024-06-20T21:27:50.356637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: DeprecationWarning: invalid escape sequence \\g\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\g\n",
      "C:\\Users\\huyinit\\AppData\\Local\\Temp\\ipykernel_6872\\3141291258.py:5: DeprecationWarning: invalid escape sequence \\g\n",
      "  model_name = \"E:\\gemma\\gemma-transformers-1.1-7b-it-v1\"\n",
      "loading configuration file E:\\gemma\\gemma-transformers-1.1-7b-it-v1\\config.json\n",
      "Model config GemmaConfig {\n",
      "  \"_name_or_path\": \"E:\\\\gemma\\\\gemma-transformers-1.1-7b-it-v1\",\n",
      "  \"architectures\": [\n",
      "    \"GemmaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"head_dim\": 256,\n",
      "  \"hidden_act\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 24576,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"gemma\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 256000\n",
      "}\n",
      "\n",
      "loading weights file E:\\gemma\\gemma-transformers-1.1-7b-it-v1\\model.safetensors.index.json\n",
      "Instantiating GemmaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35aa255634c24d19bfafa237c2270477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing GemmaForCausalLM.\n",
      "\n",
      "All the weights of GemmaForCausalLM were initialized from the model checkpoint at E:\\gemma\\gemma-transformers-1.1-7b-it-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GemmaForCausalLM for predictions without further training.\n",
      "loading configuration file E:\\gemma\\gemma-transformers-1.1-7b-it-v1\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 14.19 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Bắt đầu tính thời gian\n",
    "start_time = time.time()\n",
    "\n",
    "# Đoạn mã của bạn\n",
    "model_name = \"E:\\gemma\\gemma-transformers-1.1-7b-it-v1\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map='auto',  # Thay thế device bằng 'auto' nếu bạn chưa định nghĩa\n",
    "    torch_dtype=compute_dtype,\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "max_seq_length = 512  # 2048\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, max_seq_length=max_seq_length)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Kết thúc tính thời gian\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "print(f\"Execution time: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e29dc454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer : GemmaTokenizerFast(name_or_path='E:\\gemma\\gemma-transformers-1.1-7b-it-v1', vocab_size=256000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<bos>', 'eos_token': '<eos>', 'unk_token': '<unk>', 'pad_token': '<eos>', 'additional_special_tokens': ['<start_of_turn>', '<end_of_turn>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t1: AddedToken(\"<eos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t2: AddedToken(\"<bos>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t5: AddedToken(\"<2mass>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t6: AddedToken(\"[@BOS@]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t7: AddedToken(\"<unused0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t8: AddedToken(\"<unused1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t9: AddedToken(\"<unused2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t10: AddedToken(\"<unused3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t11: AddedToken(\"<unused4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t12: AddedToken(\"<unused5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t13: AddedToken(\"<unused6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t14: AddedToken(\"<unused7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t15: AddedToken(\"<unused8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t16: AddedToken(\"<unused9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t17: AddedToken(\"<unused10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t18: AddedToken(\"<unused11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t19: AddedToken(\"<unused12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t20: AddedToken(\"<unused13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t21: AddedToken(\"<unused14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t22: AddedToken(\"<unused15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t23: AddedToken(\"<unused16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t24: AddedToken(\"<unused17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t25: AddedToken(\"<unused18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t26: AddedToken(\"<unused19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t27: AddedToken(\"<unused20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t28: AddedToken(\"<unused21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t29: AddedToken(\"<unused22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t30: AddedToken(\"<unused23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t31: AddedToken(\"<unused24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t32: AddedToken(\"<unused25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t33: AddedToken(\"<unused26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t34: AddedToken(\"<unused27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t35: AddedToken(\"<unused28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t36: AddedToken(\"<unused29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t37: AddedToken(\"<unused30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t38: AddedToken(\"<unused31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t39: AddedToken(\"<unused32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t40: AddedToken(\"<unused33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t41: AddedToken(\"<unused34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t42: AddedToken(\"<unused35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t43: AddedToken(\"<unused36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t44: AddedToken(\"<unused37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t45: AddedToken(\"<unused38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t46: AddedToken(\"<unused39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t47: AddedToken(\"<unused40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t48: AddedToken(\"<unused41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t49: AddedToken(\"<unused42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t50: AddedToken(\"<unused43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t51: AddedToken(\"<unused44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t52: AddedToken(\"<unused45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t53: AddedToken(\"<unused46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t54: AddedToken(\"<unused47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t55: AddedToken(\"<unused48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t56: AddedToken(\"<unused49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t57: AddedToken(\"<unused50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t58: AddedToken(\"<unused51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t59: AddedToken(\"<unused52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t60: AddedToken(\"<unused53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t61: AddedToken(\"<unused54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t62: AddedToken(\"<unused55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t63: AddedToken(\"<unused56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t64: AddedToken(\"<unused57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t65: AddedToken(\"<unused58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t66: AddedToken(\"<unused59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t67: AddedToken(\"<unused60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t68: AddedToken(\"<unused61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t69: AddedToken(\"<unused62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t70: AddedToken(\"<unused63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t71: AddedToken(\"<unused64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t72: AddedToken(\"<unused65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t73: AddedToken(\"<unused66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t74: AddedToken(\"<unused67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t75: AddedToken(\"<unused68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t76: AddedToken(\"<unused69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t77: AddedToken(\"<unused70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t78: AddedToken(\"<unused71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t79: AddedToken(\"<unused72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t80: AddedToken(\"<unused73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t81: AddedToken(\"<unused74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t82: AddedToken(\"<unused75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t83: AddedToken(\"<unused76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t84: AddedToken(\"<unused77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t85: AddedToken(\"<unused78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t86: AddedToken(\"<unused79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t87: AddedToken(\"<unused80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t88: AddedToken(\"<unused81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t89: AddedToken(\"<unused82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t90: AddedToken(\"<unused83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t91: AddedToken(\"<unused84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t92: AddedToken(\"<unused85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t93: AddedToken(\"<unused86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t94: AddedToken(\"<unused87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t95: AddedToken(\"<unused88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t96: AddedToken(\"<unused89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t97: AddedToken(\"<unused90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t98: AddedToken(\"<unused91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t99: AddedToken(\"<unused92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t100: AddedToken(\"<unused93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t101: AddedToken(\"<unused94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t102: AddedToken(\"<unused95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t103: AddedToken(\"<unused96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t104: AddedToken(\"<unused97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t105: AddedToken(\"<unused98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t106: AddedToken(\"<start_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t107: AddedToken(\"<end_of_turn>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t108: AddedToken(\"\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t109: AddedToken(\"\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t110: AddedToken(\"\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t111: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t112: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t113: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t114: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t115: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t116: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t117: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t118: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t119: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t120: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t121: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t122: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t123: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t124: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t125: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t126: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t127: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t128: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t129: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t130: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t131: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t132: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t133: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t134: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t135: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t136: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t137: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t138: AddedToken(\"\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t139: AddedToken(\"▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t140: AddedToken(\"▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t141: AddedToken(\"▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t142: AddedToken(\"▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t143: AddedToken(\"▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t144: AddedToken(\"▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t145: AddedToken(\"▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t146: AddedToken(\"▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t147: AddedToken(\"▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t148: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t149: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t150: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t151: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t152: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t153: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t154: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t155: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t156: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t157: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t158: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t159: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t160: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t161: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t162: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t163: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t164: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t165: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t166: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t167: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t168: AddedToken(\"▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t169: AddedToken(\"<table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t170: AddedToken(\"<caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t171: AddedToken(\"<thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t172: AddedToken(\"<tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t173: AddedToken(\"<tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t174: AddedToken(\"<tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t175: AddedToken(\"<th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t176: AddedToken(\"<td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t177: AddedToken(\"</table>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t178: AddedToken(\"</caption>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t179: AddedToken(\"</thead>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t180: AddedToken(\"</tbody>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t181: AddedToken(\"</tfoot>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t182: AddedToken(\"</tr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t183: AddedToken(\"</th>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t184: AddedToken(\"</td>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t185: AddedToken(\"<h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t186: AddedToken(\"<h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t187: AddedToken(\"<h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t188: AddedToken(\"<h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t189: AddedToken(\"<h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t190: AddedToken(\"<h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t191: AddedToken(\"<blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t192: AddedToken(\"</h1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t193: AddedToken(\"</h2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t194: AddedToken(\"</h3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t195: AddedToken(\"</h4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t196: AddedToken(\"</h5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t197: AddedToken(\"</h6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t198: AddedToken(\"</blockquote>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t199: AddedToken(\"<strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t200: AddedToken(\"<em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t201: AddedToken(\"<b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t202: AddedToken(\"<i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t203: AddedToken(\"<u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t204: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t205: AddedToken(\"<sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t206: AddedToken(\"<sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t207: AddedToken(\"<code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t208: AddedToken(\"</strong>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t209: AddedToken(\"</em>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t210: AddedToken(\"</b>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t211: AddedToken(\"</i>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t212: AddedToken(\"</u>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t213: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t214: AddedToken(\"</sub>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t215: AddedToken(\"</sup>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "\t216: AddedToken(\"</code>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
      "}\n",
      "Tokenizer pad_token_id: 1\n",
      "Tokenizer eos_token_id: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In kết quả của tokenizer\n",
    "print(f\"Tokenizer : {tokenizer}\")\n",
    "print(f\"Tokenizer pad_token_id: {tokenizer.pad_token_id}\")\n",
    "print(f\"Tokenizer eos_token_id: {tokenizer.eos_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5496c9bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:29:38.396757Z",
     "iopub.status.busy": "2024-06-20T21:29:38.396457Z",
     "iopub.status.idle": "2024-06-20T21:29:38.403243Z",
     "shell.execute_reply": "2024-06-20T21:29:38.402425Z"
    },
    "papermill": {
     "duration": 0.020786,
     "end_time": "2024-06-20T21:29:38.405103",
     "exception": false,
     "start_time": "2024-06-20T21:29:38.384317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(X_test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        prompt = X_test.iloc[i][\"text\"]\n",
    "        pipe = pipeline(task=\"text-generation\", \n",
    "                        model=model, \n",
    "                        tokenizer=tokenizer, \n",
    "                        max_new_tokens = 1, \n",
    "                        temperature = 0.0,\n",
    "                       )\n",
    "        result = pipe(prompt)\n",
    "        answer = result[0]['generated_text'].split(\"=\")[-1]\n",
    "        if \"positive\" in answer:\n",
    "            y_pred.append(\"positive\")\n",
    "        elif \"negative\" in answer:\n",
    "            y_pred.append(\"negative\")\n",
    "        elif \"neutral\" in answer:\n",
    "            y_pred.append(\"neutral\")\n",
    "        else:\n",
    "            y_pred.append(\"none\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "432c503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f934ced",
   "metadata": {
    "papermill": {
     "duration": 0.010771,
     "end_time": "2024-06-20T21:29:38.427142",
     "exception": false,
     "start_time": "2024-06-20T21:29:38.416371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At this point, we are ready to test the Llama 3 8b-chat-hf model and see how it performs on our problem without any fine-tuning. This allows us to get insights on the model itself and establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7964cc25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:29:38.450231Z",
     "iopub.status.busy": "2024-06-20T21:29:38.449971Z",
     "iopub.status.idle": "2024-06-20T21:35:06.128568Z",
     "shell.execute_reply": "2024-06-20T21:35:06.127466Z"
    },
    "papermill": {
     "duration": 327.692355,
     "end_time": "2024-06-20T21:35:06.130523",
     "exception": false,
     "start_time": "2024-06-20T21:29:38.438168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/970 [00:00<?, ?it/s]c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 970/970 [01:56<00:00,  8.35it/s]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0096410",
   "metadata": {
    "papermill": {
     "duration": 0.078974,
     "end_time": "2024-06-20T21:35:06.289711",
     "exception": false,
     "start_time": "2024-06-20T21:35:06.210737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the following cell, we evaluate the results. There is little to be said, it is performing really terribly because the 8b-chat-hf model tends to just predict a neutral sentiment and seldom it detects positive or negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "859d0552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:35:06.450250Z",
     "iopub.status.busy": "2024-06-20T21:35:06.449863Z",
     "iopub.status.idle": "2024-06-20T21:35:06.470678Z",
     "shell.execute_reply": "2024-06-20T21:35:06.469800Z"
    },
    "papermill": {
     "duration": 0.103318,
     "end_time": "2024-06-20T21:35:06.472467",
     "exception": false,
     "start_time": "2024-06-20T21:35:06.369149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.594\n",
      "Accuracy for label 0: 0.000\n",
      "Accuracy for label 1: 1.000\n",
      "Accuracy for label 2: 0.000\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       121\n",
      "           1       0.59      1.00      0.75       576\n",
      "           2       0.00      0.00      0.00       273\n",
      "\n",
      "    accuracy                           0.59       970\n",
      "   macro avg       0.20      0.33      0.25       970\n",
      "weighted avg       0.35      0.59      0.44       970\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  0 121   0]\n",
      " [  0 576   0]\n",
      " [  0 273   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c8ca9d",
   "metadata": {
    "papermill": {
     "duration": 0.079321,
     "end_time": "2024-06-20T21:35:06.631557",
     "exception": false,
     "start_time": "2024-06-20T21:35:06.552236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12675811",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:35:06.953374Z",
     "iopub.status.busy": "2024-06-20T21:35:06.953042Z",
     "iopub.status.idle": "2024-06-20T21:35:06.959429Z",
     "shell.execute_reply": "2024-06-20T21:35:06.958650Z"
    },
    "papermill": {
     "duration": 0.089793,
     "end_time": "2024-06-20T21:35:06.961309",
     "exception": false,
     "start_time": "2024-06-20T21:35:06.871516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import (accuracy_score, \n",
    "                             recall_score, \n",
    "                             precision_score, \n",
    "                             f1_score)\n",
    "\n",
    "from transformers import EarlyStoppingCallback, IntervalStrategy\n",
    "\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de943e2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:35:07.123517Z",
     "iopub.status.busy": "2024-06-20T21:35:07.122876Z",
     "iopub.status.idle": "2024-06-20T21:35:10.088120Z",
     "shell.execute_reply": "2024-06-20T21:35:10.087419Z"
    },
    "papermill": {
     "duration": 3.04909,
     "end_time": "2024-06-20T21:35:10.090159",
     "exception": false,
     "start_time": "2024-06-20T21:35:07.041069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field, max_seq_length, dataset_kwargs. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "PyTorch: setting up devices\n",
      "PyTorch: setting up devices\n",
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:285: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:323: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:329: UserWarning: You passed a `dataset_kwargs` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba2a05bf7f44a41b2ca8c210ce27479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2909 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66538b2391a94151986b579b68e6fc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/967 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\trl\\trainer\\sft_trainer.py:398: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "output_dir=\"trained_weigths\"\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,                    # directory to save and repository id\n",
    "    num_train_epochs=5,                       # number of training epochs\n",
    "    per_device_train_batch_size=1,            # batch size per device during training\n",
    "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,                         # log every 10 steps\n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=False,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    # report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
    "    #evaluation_strategy=\"steps\",              # save checkpoint every epoch\n",
    "    #load_best_model_at_end = True,\n",
    "    #eval_steps = 25,\n",
    "    #metric_for_best_model = 'accuracy',\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    },\n",
    "    #compute_metrics=compute_metrics,\n",
    "    #callbacks = [EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129678a",
   "metadata": {
    "papermill": {
     "duration": 0.07897,
     "end_time": "2024-06-20T21:35:10.249984",
     "exception": false,
     "start_time": "2024-06-20T21:35:10.171014",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code will train the model using the trainer.train() method and then save the trained model to the trained-model directory. Using The standard GPU P100 offered by Kaggle, the training should be quite fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6e43df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Debug start _inner_training_loop :****\n",
      "Currently training with a batch size of: 1\n",
      "***** Running training *****\n",
      "  Num examples = 2,909\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 1,815\n",
      "  Number of trainable parameters = 200,015,872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start def train(self, *args, **kwargs):\n",
      "start super().train(*args, **kwargs)\n",
      "Train! inner:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12f06f30db24ac5880cf2d5e6722a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1815 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch : 0\n",
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\torch\\utils\\checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4819, 'grad_norm': 1.4594395160675049, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.07}\n",
      "{'loss': 1.2559, 'grad_norm': 1.1500604152679443, 'learning_rate': 0.00018181818181818183, 'epoch': 0.14}\n",
      "{'loss': 1.0858, 'grad_norm': 0.6350141167640686, 'learning_rate': 0.0001999362825656992, 'epoch': 0.21}\n",
      "{'loss': 1.0584, 'grad_norm': 0.6502953171730042, 'learning_rate': 0.00019967756964555045, 'epoch': 0.28}\n",
      "{'loss': 0.9899, 'grad_norm': 0.6841915845870972, 'learning_rate': 0.00019922039361395185, 'epoch': 0.34}\n",
      "{'loss': 0.9924, 'grad_norm': 0.6516330242156982, 'learning_rate': 0.00019856566473163746, 'epoch': 0.41}\n",
      "{'loss': 0.9792, 'grad_norm': 0.8412651419639587, 'learning_rate': 0.00019771468659711595, 'epoch': 0.48}\n",
      "{'loss': 0.9978, 'grad_norm': 0.5898518562316895, 'learning_rate': 0.00019666915355113975, 'epoch': 0.55}\n",
      "{'loss': 0.9538, 'grad_norm': 0.6696980595588684, 'learning_rate': 0.0001954311473031864, 'epoch': 0.62}\n",
      "{'loss': 0.9592, 'grad_norm': 0.7401172518730164, 'learning_rate': 0.00019400313278666902, 'epoch': 0.69}\n",
      "{'loss': 0.889, 'grad_norm': 0.5592634081840515, 'learning_rate': 0.0001923879532511287, 'epoch': 0.76}\n",
      "{'loss': 0.9249, 'grad_norm': 0.6929619908332825, 'learning_rate': 0.00019058882460117974, 'epoch': 0.83}\n",
      "{'loss': 0.9086, 'grad_norm': 0.6018999218940735, 'learning_rate': 0.00018860932899348028, 'epoch': 0.89}\n",
      "{'loss': 0.9052, 'grad_norm': 0.8535116314888, 'learning_rate': 0.00018645340770447595, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8302, 'grad_norm': 0.6910934448242188, 'learning_rate': 0.00018412535328311814, 'epoch': 1.03}\n",
      "{'loss': 0.7418, 'grad_norm': 0.6784517765045166, 'learning_rate': 0.0001816298010041806, 'epoch': 1.1}\n",
      "{'loss': 0.7193, 'grad_norm': 0.5864966511726379, 'learning_rate': 0.0001789717196391916, 'epoch': 1.17}\n",
      "{'loss': 0.7052, 'grad_norm': 0.6511955261230469, 'learning_rate': 0.00017615640156335712, 'epoch': 1.24}\n",
      "{'loss': 0.692, 'grad_norm': 0.7553870677947998, 'learning_rate': 0.00017318945221817255, 'epoch': 1.31}\n",
      "{'loss': 0.7156, 'grad_norm': 0.5481001734733582, 'learning_rate': 0.00017007677895070357, 'epoch': 1.38}\n",
      "{'loss': 0.7152, 'grad_norm': 0.5327635407447815, 'learning_rate': 0.00016682457925175763, 'epoch': 1.44}\n",
      "{'loss': 0.762, 'grad_norm': 0.545109212398529, 'learning_rate': 0.00016343932841636456, 'epoch': 1.51}\n",
      "{'loss': 0.7089, 'grad_norm': 0.5970158576965332, 'learning_rate': 0.0001599277666511347, 'epoch': 1.58}\n",
      "{'loss': 0.7543, 'grad_norm': 0.6380588412284851, 'learning_rate': 0.00015629688565416478, 'epoch': 1.65}\n",
      "{'loss': 0.7182, 'grad_norm': 0.6613101363182068, 'learning_rate': 0.00015255391469421128, 'epoch': 1.72}\n",
      "{'loss': 0.69, 'grad_norm': 0.4973536729812622, 'learning_rate': 0.00014870630621684872, 'epoch': 1.79}\n",
      "{'loss': 0.7423, 'grad_norm': 0.6343316435813904, 'learning_rate': 0.00014476172100627127, 'epoch': 1.86}\n",
      "{'loss': 0.7161, 'grad_norm': 0.5679279565811157, 'learning_rate': 0.00014072801293228188, 'epoch': 1.93}\n",
      "{'loss': 0.7545, 'grad_norm': 0.5498722791671753, 'learning_rate': 0.00013661321331283796, 'epoch': 1.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4552, 'grad_norm': 0.6802445650100708, 'learning_rate': 0.00013242551492328875, 'epoch': 2.06}\n",
      "{'loss': 0.4299, 'grad_norm': 0.8375889658927917, 'learning_rate': 0.00012817325568414297, 'epoch': 2.13}\n",
      "{'loss': 0.4199, 'grad_norm': 0.5536882877349854, 'learning_rate': 0.00012386490205984488, 'epoch': 2.2}\n",
      "{'loss': 0.4298, 'grad_norm': 0.6665387153625488, 'learning_rate': 0.00011950903220161285, 'epoch': 2.27}\n",
      "{'loss': 0.4437, 'grad_norm': 0.8988458514213562, 'learning_rate': 0.00011511431886790407, 'epoch': 2.34}\n",
      "{'loss': 0.4399, 'grad_norm': 0.6777801513671875, 'learning_rate': 0.00011068951215651132, 'epoch': 2.41}\n",
      "{'loss': 0.4447, 'grad_norm': 0.6529946327209473, 'learning_rate': 0.00010624342208267292, 'epoch': 2.48}\n",
      "{'loss': 0.4497, 'grad_norm': 0.5233761668205261, 'learning_rate': 0.0001017849010378846, 'epoch': 2.54}\n",
      "{'loss': 0.4283, 'grad_norm': 0.8006649613380432, 'learning_rate': 9.732282616433756e-05, 'epoch': 2.61}\n",
      "{'loss': 0.4359, 'grad_norm': 0.6416663527488708, 'learning_rate': 9.286608168007678e-05, 'epoch': 2.68}\n",
      "{'loss': 0.4391, 'grad_norm': 0.7326506972312927, 'learning_rate': 8.842354119007099e-05, 'epoch': 2.75}\n",
      "{'loss': 0.4434, 'grad_norm': 0.6573342680931091, 'learning_rate': 8.400405001841399e-05, 'epoch': 2.82}\n",
      "{'loss': 0.431, 'grad_norm': 0.7353219389915466, 'learning_rate': 7.961640759683416e-05, 'epoch': 2.89}\n",
      "{'loss': 0.4497, 'grad_norm': 0.7515250444412231, 'learning_rate': 7.526934994457844e-05, 'epoch': 2.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3575, 'grad_norm': 0.4743308424949646, 'learning_rate': 7.097153227455379e-05, 'epoch': 3.03}\n",
      "{'loss': 0.2284, 'grad_norm': 0.5421464443206787, 'learning_rate': 6.673151176035762e-05, 'epoch': 3.09}\n",
      "{'loss': 0.231, 'grad_norm': 0.5631994009017944, 'learning_rate': 6.25577304985103e-05, 'epoch': 3.16}\n",
      "{'loss': 0.2399, 'grad_norm': 0.5290246605873108, 'learning_rate': 5.845849869981137e-05, 'epoch': 3.23}\n",
      "{'loss': 0.2403, 'grad_norm': 0.4836066961288452, 'learning_rate': 5.4441978143287066e-05, 'epoch': 3.3}\n",
      "{'loss': 0.2371, 'grad_norm': 0.5625641345977783, 'learning_rate': 5.051616592567323e-05, 'epoch': 3.37}\n",
      "{'loss': 0.2474, 'grad_norm': 0.8049702048301697, 'learning_rate': 4.668887853878896e-05, 'epoch': 3.44}\n",
      "{'loss': 0.237, 'grad_norm': 0.6854503750801086, 'learning_rate': 4.296773630650358e-05, 'epoch': 3.51}\n",
      "{'loss': 0.2262, 'grad_norm': 0.5659397840499878, 'learning_rate': 3.9360148212284475e-05, 'epoch': 3.58}\n",
      "{'loss': 0.2339, 'grad_norm': 0.551835298538208, 'learning_rate': 3.5873297147533915e-05, 'epoch': 3.64}\n",
      "{'loss': 0.2414, 'grad_norm': 0.8913436532020569, 'learning_rate': 3.2514125610086955e-05, 'epoch': 3.71}\n",
      "{'loss': 0.2293, 'grad_norm': 0.5813140273094177, 'learning_rate': 2.9289321881345254e-05, 'epoch': 3.78}\n",
      "{'loss': 0.2308, 'grad_norm': 0.5912068486213684, 'learning_rate': 2.6205306709568354e-05, 'epoch': 3.85}\n",
      "{'loss': 0.2379, 'grad_norm': 0.6995547413825989, 'learning_rate': 2.3268220525837437e-05, 'epoch': 3.92}\n",
      "{'loss': 0.2275, 'grad_norm': 0.6837644577026367, 'learning_rate': 2.0483911218144715e-05, 'epoch': 3.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Epoch : 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1706, 'grad_norm': 0.5493859648704529, 'learning_rate': 1.7857922487950874e-05, 'epoch': 4.06}\n",
      "{'loss': 0.1554, 'grad_norm': 0.39107540249824524, 'learning_rate': 1.5395482812393514e-05, 'epoch': 4.13}\n",
      "{'loss': 0.1534, 'grad_norm': 0.3682272434234619, 'learning_rate': 1.3101495034123313e-05, 'epoch': 4.19}\n",
      "{'loss': 0.1641, 'grad_norm': 0.5411484837532043, 'learning_rate': 1.0980526599494733e-05, 'epoch': 4.26}\n",
      "{'loss': 0.1575, 'grad_norm': 0.48541510105133057, 'learning_rate': 9.036800464548157e-06, 'epoch': 4.33}\n",
      "{'loss': 0.1575, 'grad_norm': 0.5195474624633789, 'learning_rate': 7.2741866868895395e-06, 'epoch': 4.4}\n",
      "{'loss': 0.1546, 'grad_norm': 0.4063849151134491, 'learning_rate': 5.696194720208792e-06, 'epoch': 4.47}\n",
      "{'loss': 0.1498, 'grad_norm': 0.5368598699569702, 'learning_rate': 4.305966426779118e-06, 'epoch': 4.54}\n",
      "{'loss': 0.164, 'grad_norm': 0.7164586186408997, 'learning_rate': 3.1062698218492724e-06, 'epoch': 4.61}\n",
      "{'loss': 0.1616, 'grad_norm': 0.502795934677124, 'learning_rate': 2.0994935623844692e-06, 'epoch': 4.68}\n",
      "{'loss': 0.1581, 'grad_norm': 0.7097626328468323, 'learning_rate': 1.2876421911288905e-06, 'epoch': 4.74}\n",
      "{'loss': 0.1553, 'grad_norm': 0.386167973279953, 'learning_rate': 6.723321454590092e-07, 'epoch': 4.81}\n",
      "{'loss': 0.1559, 'grad_norm': 0.4139557480812073, 'learning_rate': 2.547885389746485e-07, 'epoch': 4.88}\n",
      "{'loss': 0.1555, 'grad_norm': 0.5693489909172058, 'learning_rate': 3.584272223546847e-08, 'epoch': 4.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 27712.4243, 'train_samples_per_second': 0.525, 'train_steps_per_second': 0.065, 'train_loss': 0.5570154850804773, 'epoch': 4.99}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1815, training_loss=0.5570154850804773, metrics={'train_runtime': 27712.4243, 'train_samples_per_second': 0.525, 'train_steps_per_second': 0.065, 'total_flos': 5.91609879430656e+16, 'train_loss': 0.5570154850804773, 'epoch': 4.99140598143692})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c44d46c",
   "metadata": {
    "papermill": {
     "duration": 0.080058,
     "end_time": "2024-06-20T23:12:53.967740",
     "exception": false,
     "start_time": "2024-06-20T23:12:53.887682",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model and the tokenizer are saved to disk for later usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58941266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T23:12:54.129906Z",
     "iopub.status.busy": "2024-06-20T23:12:54.129530Z",
     "iopub.status.idle": "2024-06-20T23:12:55.802127Z",
     "shell.execute_reply": "2024-06-20T23:12:55.801137Z"
    },
    "papermill": {
     "duration": 1.756601,
     "end_time": "2024-06-20T23:12:55.804545",
     "exception": false,
     "start_time": "2024-06-20T23:12:54.047944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to trained_weigths\n",
      "loading configuration file E:\\gemma\\gemma-transformers-1.1-7b-it-v1\\config.json\n",
      "Model config GemmaConfig {\n",
      "  \"architectures\": [\n",
      "    \"GemmaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"head_dim\": 256,\n",
      "  \"hidden_act\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 24576,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"gemma\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 256000\n",
      "}\n",
      "\n",
      "tokenizer config file saved in trained_weigths\\tokenizer_config.json\n",
      "Special tokens file saved in trained_weigths\\special_tokens_map.json\n",
      "tokenizer config file saved in trained_weigths\\tokenizer_config.json\n",
      "Special tokens file saved in trained_weigths\\special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('trained_weigths\\\\tokenizer_config.json',\n",
       " 'trained_weigths\\\\special_tokens_map.json',\n",
       " 'trained_weigths\\\\tokenizer.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model()\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57d92a",
   "metadata": {
    "papermill": {
     "duration": 0.079959,
     "end_time": "2024-06-20T23:12:55.965656",
     "exception": false,
     "start_time": "2024-06-20T23:12:55.885697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Afterwards, loading the TensorBoard extension and start TensorBoard, pointing to the logs/runs directory, which is assumed to contain the training logs and checkpoints for your model, will allow you to understand how the models fits during the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cb5884",
   "metadata": {
    "papermill": {
     "duration": 0.087667,
     "end_time": "2024-06-20T23:13:02.350704",
     "exception": false,
     "start_time": "2024-06-20T23:13:02.263037",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2dafb5",
   "metadata": {
    "papermill": {
     "duration": 0.0822,
     "end_time": "2024-06-20T23:13:02.520927",
     "exception": false,
     "start_time": "2024-06-20T23:13:02.438727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code will first predict the sentiment labels for the test set using the predict() function. Then, it will evaluate the model's performance on the test set using the evaluate() function. The result now should be impressive with an overall accuracy of over 0.8 and high accuracy, precision and recall for the single sentiment labels. The prediction of the neutral label can still be improved, yet it is impressive how much could be done with little data and some fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0479fbf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T23:13:02.698193Z",
     "iopub.status.busy": "2024-06-20T23:13:02.697380Z",
     "iopub.status.idle": "2024-06-20T23:19:07.764652Z",
     "shell.execute_reply": "2024-06-20T23:19:07.763596Z"
    },
    "papermill": {
     "duration": 365.151257,
     "end_time": "2024-06-20T23:19:07.766680",
     "exception": false,
     "start_time": "2024-06-20T23:13:02.615423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/970 [00:00<?, ?it/s]c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
      "c:\\Users\\huyinit\\anaconda3\\envs\\llama3_212\\lib\\site-packages\\torch\\utils\\checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 970/970 [26:27<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.869\n",
      "Accuracy for label 0: 0.860\n",
      "Accuracy for label 1: 0.911\n",
      "Accuracy for label 2: 0.784\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89       121\n",
      "           1       0.88      0.91      0.89       576\n",
      "           2       0.84      0.78      0.81       273\n",
      "\n",
      "    accuracy                           0.87       970\n",
      "   macro avg       0.87      0.85      0.86       970\n",
      "weighted avg       0.87      0.87      0.87       970\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[104  16   1]\n",
      " [ 10 525  41]\n",
      " [  0  59 214]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_test, model, tokenizer)\n",
    "evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a320f1ed",
   "metadata": {
    "papermill": {
     "duration": 0.148146,
     "end_time": "2024-06-20T23:19:08.064687",
     "exception": false,
     "start_time": "2024-06-20T23:19:07.916541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The following code will create a Pandas DataFrame called evaluation containing the text, true labels, and predicted labels from the test set. This is expectially useful for understanding the errors that the fine-tuned model makes, and gettting insights on how to improve the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce1c5aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T23:19:08.364899Z",
     "iopub.status.busy": "2024-06-20T23:19:08.364197Z",
     "iopub.status.idle": "2024-06-20T23:19:08.388932Z",
     "shell.execute_reply": "2024-06-20T23:19:08.388237Z"
    },
    "papermill": {
     "duration": 0.176911,
     "end_time": "2024-06-20T23:19:08.390850",
     "exception": false,
     "start_time": "2024-06-20T23:19:08.213939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluation = pd.DataFrame({'text': X_test[\"text\"], \n",
    "                           'y_true':y_true, \n",
    "                           'y_pred': y_pred},\n",
    "                         )\n",
    "evaluation.to_csv(\"test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecdb8cd",
   "metadata": {
    "papermill": {
     "duration": 0.148145,
     "end_time": "2024-06-20T23:19:08.749500",
     "exception": false,
     "start_time": "2024-06-20T23:19:08.601355",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The evaluation results are indeed good when compared to simpler benchmarks such as a CONV1D + bidirectional LSTM based model () such as: https://www.kaggle.com/code/lucamassaron/lstm-baseline-for-sentiment-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8a2c5b",
   "metadata": {
    "papermill": {
     "duration": 0.149606,
     "end_time": "2024-06-20T23:19:09.048527",
     "exception": false,
     "start_time": "2024-06-20T23:19:08.898921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Here are the results of the baseline model:\n",
    "\n",
    "Accuracy: 0.623\n",
    "Accuracy for label 0: 0.620\n",
    "Accuracy for label 1: 0.590\n",
    "Accuracy for label 2: 0.660\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.79      0.62      0.69       300\n",
    "           1       0.61      0.59      0.60       300\n",
    "           2       0.53      0.66      0.59       300\n",
    "\n",
    "    accuracy                           0.62       900\n",
    "   macro avg       0.64      0.62      0.63       900\n",
    "weighted avg       0.64      0.62      0.63       900\n",
    "\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "[[186  39  75]\\\n",
    " [ 23 177 100]\\\n",
    " [ 27  75 198]]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b2be3",
   "metadata": {
    "papermill": {
     "duration": 0.150471,
     "end_time": "2024-06-20T23:19:09.361193",
     "exception": false,
     "start_time": "2024-06-20T23:19:09.210722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "With this testing, the fine-tuning of Llama 3 has reached its conclusion. Dont't forget to upvote if you find the notebook useful for your projects or work! "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 622510,
     "sourceId": 1192499,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "llama3_212",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6838.673758,
   "end_time": "2024-06-20T23:19:12.346812",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-20T21:25:13.673054",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00d8d3148d174c20b5e91b8147fdbcd4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b899350b67349b2b940186b84946a53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_37c18815c6664d2eab7b5cb3a8c993bc",
        "IPY_MODEL_8496dd2d1c3642b0b31e63b3091c65ea",
        "IPY_MODEL_9d820edaebd24601bfa027c079c12155"
       ],
       "layout": "IPY_MODEL_00d8d3148d174c20b5e91b8147fdbcd4"
      }
     },
     "29015cb862314aa1b112c42770e1c3e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b875d46b3d344b9bee90938d70f331c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d5cc86756e2478fb361507e7f07a4e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2f5ba648f1ff49e3ab198f0852e72891": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_988c04b443e74e5bbe9222a44ba51775",
       "max": 900,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d811750bf1144d10b824b893b2ea260d",
       "value": 900
      }
     },
     "2f74bc32c08842a8b0b4009b52a79512": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "346509a3d92948aeb5c0ac773dfb42b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37c18815c6664d2eab7b5cb3a8c993bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_29015cb862314aa1b112c42770e1c3e2",
       "placeholder": "​",
       "style": "IPY_MODEL_a315751b5d13489dbef67d7006b104b7",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "57c5ffa894a74a8faaed08fc88d4d2ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5bbec511bbae4591995c7a78e6b0c80b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_346509a3d92948aeb5c0ac773dfb42b9",
       "placeholder": "​",
       "style": "IPY_MODEL_8c82fee8112a4c38a4d4b37a641a7831",
       "value": " 900/900 [00:00&lt;00:00, 4069.54 examples/s]"
      }
     },
     "5f064603cb9a4b5a9d674bf08c3824bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5e0e10bafb640b68962698a4cbb5638",
       "placeholder": "​",
       "style": "IPY_MODEL_2d5cc86756e2478fb361507e7f07a4e3",
       "value": "Map: 100%"
      }
     },
     "7743078c7fc743ae9dd7d5217aefb511": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8496dd2d1c3642b0b31e63b3091c65ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7743078c7fc743ae9dd7d5217aefb511",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cbe68a0487f54bbdbdcaae752d2545e2",
       "value": 4
      }
     },
     "8b562ece5ce246859b435c3b0955f815": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5f064603cb9a4b5a9d674bf08c3824bb",
        "IPY_MODEL_2f5ba648f1ff49e3ab198f0852e72891",
        "IPY_MODEL_5bbec511bbae4591995c7a78e6b0c80b"
       ],
       "layout": "IPY_MODEL_2b875d46b3d344b9bee90938d70f331c"
      }
     },
     "8c82fee8112a4c38a4d4b37a641a7831": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "988c04b443e74e5bbe9222a44ba51775": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d820edaebd24601bfa027c079c12155": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2f74bc32c08842a8b0b4009b52a79512",
       "placeholder": "​",
       "style": "IPY_MODEL_57c5ffa894a74a8faaed08fc88d4d2ec",
       "value": " 4/4 [01:46&lt;00:00, 22.84s/it]"
      }
     },
     "a315751b5d13489dbef67d7006b104b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5e0e10bafb640b68962698a4cbb5638": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbe68a0487f54bbdbdcaae752d2545e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d811750bf1144d10b824b893b2ea260d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
