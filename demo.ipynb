{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3f54a6",
   "metadata": {
    "papermill": {
     "duration": 0.010876,
     "end_time": "2024-06-20T21:25:16.435773",
     "exception": false,
     "start_time": "2024-06-20T21:25:16.424897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8e5646",
   "metadata": {
    "papermill": {
     "duration": 0.011015,
     "end_time": "2024-06-20T21:25:16.497909",
     "exception": false,
     "start_time": "2024-06-20T21:25:16.486894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d861896",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:29.855163Z",
     "iopub.status.busy": "2024-06-20T21:27:29.854854Z",
     "iopub.status.idle": "2024-06-20T21:27:29.859361Z",
     "shell.execute_reply": "2024-06-20T21:27:29.858514Z"
    },
    "papermill": {
     "duration": 0.018282,
     "end_time": "2024-06-20T21:27:29.861276",
     "exception": false,
     "start_time": "2024-06-20T21:27:29.842994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11dca30b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:29.904828Z",
     "iopub.status.busy": "2024-06-20T21:27:29.904312Z",
     "iopub.status.idle": "2024-06-20T21:27:29.908161Z",
     "shell.execute_reply": "2024-06-20T21:27:29.907295Z"
    },
    "papermill": {
     "duration": 0.017308,
     "end_time": "2024-06-20T21:27:29.910006",
     "exception": false,
     "start_time": "2024-06-20T21:27:29.892698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92fbb06e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:29.952830Z",
     "iopub.status.busy": "2024-06-20T21:27:29.952537Z",
     "iopub.status.idle": "2024-06-20T21:27:48.655310Z",
     "shell.execute_reply": "2024-06-20T21:27:48.654351Z"
    },
    "papermill": {
     "duration": 18.716333,
     "end_time": "2024-06-20T21:27:48.657670",
     "exception": false,
     "start_time": "2024-06-20T21:27:29.941337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected accelerate version: 0.34.2\n",
      "Detected bitsandbytes version: 0.44.1\n",
      "Detected datasets version: 3.0.1\n",
      "Detected jinja2 version: 2.11.3\n",
      "Detected nltk version: 3.7\n",
      "Detected pandas version: 1.4.2\n",
      "Detected peft version: 0.13.0\n",
      "Detected psutil version: 5.8.0\n",
      "Detected pytest version: 7.1.1\n",
      "Detected safetensors version: 0.4.5\n",
      "Detected scipy version: 1.7.3\n",
      "Detected tokenizers version: 0.19.1\n",
      "Detected torchvision version: 0.15.2+cu117\n",
      "Detected torch version: 2.1.2+cu118\n",
      "Detected PIL version 9.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_default_log_level: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected rich version: 13.9.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to import libraries: 4.65 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Bắt đầu tính thời gian\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "from trl import SFTTrainer\n",
    "from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Kết thúc tính thời gian\n",
    "end_time = time.time()\n",
    "print(f\"Time to import libraries: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a43dfa",
   "metadata": {
    "papermill": {
     "duration": 0.010576,
     "end_time": "2024-06-20T21:27:48.787897",
     "exception": false,
     "start_time": "2024-06-20T21:27:48.777321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preparing the data and the core evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ceca451c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:48.831979Z",
     "iopub.status.busy": "2024-06-20T21:27:48.831740Z",
     "iopub.status.idle": "2024-06-20T21:27:50.245342Z",
     "shell.execute_reply": "2024-06-20T21:27:50.244625Z"
    },
    "papermill": {
     "duration": 1.427479,
     "end_time": "2024-06-20T21:27:50.247666",
     "exception": false,
     "start_time": "2024-06-20T21:27:48.820187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point[\"text\"]}] = {data_point[\"sentiment\"]}\n",
    "            \"\"\".strip()\n",
    "\n",
    "def generate_test_prompt(data_point):\n",
    "    return f\"\"\"\n",
    "            Analyze the sentiment of the news headline enclosed in square brackets, \n",
    "            determine if it is positive, neutral, or negative, and return the answer as \n",
    "            the corresponding sentiment label \"positive\" or \"neutral\" or \"negative\".\n",
    "\n",
    "            [{data_point}] = \"\"\".strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53012149",
   "metadata": {},
   "source": [
    "## predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbaa91b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, model, tokenizer):\n",
    "    y_pred = []\n",
    "    # for i in tqdm(range(len(X_test))):\n",
    "        # prompt = X_test.iloc[i][\"text\"]\n",
    "    prompt = generate_test_prompt(X_test)\n",
    "    # print(prompt)\n",
    "    pipe = pipeline(task=\"text-generation\", \n",
    "                    model=model, \n",
    "                    tokenizer=tokenizer, \n",
    "                    max_new_tokens = 1, \n",
    "                    temperature = 0.0,\n",
    "                    )\n",
    "    result = pipe(prompt)\n",
    "    answer = result[0]['generated_text'].split(\"=\")[-1]\n",
    "    if \"positive\" in answer:\n",
    "        y_pred.append(\"positive\")\n",
    "    elif \"negative\" in answer:\n",
    "        y_pred.append(\"negative\")\n",
    "    elif \"neutral\" in answer:\n",
    "        y_pred.append(\"neutral\")\n",
    "    else:\n",
    "        y_pred.append(\"none\")\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe3f54",
   "metadata": {
    "papermill": {
     "duration": 0.010322,
     "end_time": "2024-06-20T21:27:50.324139",
     "exception": false,
     "start_time": "2024-06-20T21:27:50.313817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load all the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bbc69",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "044b5096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T21:27:50.368804Z",
     "iopub.status.busy": "2024-06-20T21:27:50.368264Z",
     "iopub.status.idle": "2024-06-20T21:29:38.348692Z",
     "shell.execute_reply": "2024-06-20T21:29:38.347700Z"
    },
    "papermill": {
     "duration": 107.994237,
     "end_time": "2024-06-20T21:29:38.350874",
     "exception": false,
     "start_time": "2024-06-20T21:27:50.356637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file E:\\gemma\\gemma-transformers-1.1-7b-it-v1\\config.json\n",
      "Model config GemmaConfig {\n",
      "  \"_name_or_path\": \"E:\\\\gemma\\\\gemma-transformers-1.1-7b-it-v1\",\n",
      "  \"architectures\": [\n",
      "    \"GemmaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"head_dim\": 256,\n",
      "  \"hidden_act\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_activation\": \"gelu_pytorch_tanh\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 24576,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"gemma\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 16,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 256000\n",
      "}\n",
      "\n",
      "loading weights file E:\\gemma\\gemma-transformers-1.1-7b-it-v1\\model.safetensors.index.json\n",
      "Instantiating GemmaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c37921e4b7b4bfa8a14ad57d910fc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing GemmaForCausalLM.\n",
      "\n",
      "All the weights of GemmaForCausalLM were initialized from the model checkpoint at E:\\gemma\\gemma-transformers-1.1-7b-it-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GemmaForCausalLM for predictions without further training.\n",
      "loading configuration file E:\\gemma\\gemma-transformers-1.1-7b-it-v1\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file E:\\gemma\\gemma-transformers-2b-it-v3\\config.json\n",
      "Model config GemmaConfig {\n",
      "  \"_name_or_path\": \"E:\\\\gemma\\\\gemma-transformers-2b-it-v3\",\n",
      "  \"architectures\": [\n",
      "    \"GemmaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"head_dim\": 256,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_activation\": null,\n",
      "  \"hidden_size\": 2048,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 16384,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"gemma\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 18,\n",
      "  \"num_key_value_heads\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 256000\n",
      "}\n",
      "\n",
      "loading weights file E:\\gemma\\gemma-transformers-2b-it-v3\\model.safetensors.index.json\n",
      "Instantiating GemmaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 26.53 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dfc93bc5f8c4286a7718861b150dc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing GemmaForCausalLM.\n",
      "\n",
      "All the weights of GemmaForCausalLM were initialized from the model checkpoint at E:\\gemma\\gemma-transformers-2b-it-v3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GemmaForCausalLM for predictions without further training.\n",
      "loading configuration file E:\\gemma\\gemma-transformers-2b-it-v3\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 2,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0\n",
      "}\n",
      "\n",
      "loading file tokenizer.model\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading configuration file E:\\llama\\llama-3-transformers-8b-chat-hf-v1\\config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"E:\\\\llama\\\\llama-3-transformers-8b-chat-hf-v1\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "loading weights file E:\\llama\\llama-3-transformers-8b-chat-hf-v1\\model.safetensors.index.json\n",
      "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 8.22 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f63a39207804c0f8809f6f73f89c625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at E:\\llama\\llama-3-transformers-8b-chat-hf-v1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file E:\\llama\\llama-3-transformers-8b-chat-hf-v1\\generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001\n",
      "}\n",
      "\n",
      "loading file tokenizer.json\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 19.61 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "def load_model_and_tokenizer(model_path: str, max_seq_length: int = 512):\n",
    "    # Bắt đầu tính thời gian\n",
    "    start_time = time.time()\n",
    "\n",
    "    compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=False,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "    )\n",
    "\n",
    "    device_map = {\n",
    "        \"\": \"cuda\",  # Đặt phần lớn trên CPU\n",
    "        \"transformer.h\": \"cuda\",  # Đặt phần mô hình trên GPU\n",
    "    }\n",
    "        \n",
    "    # Tải mô hình\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_path,\n",
    "        device_map=device_map,\n",
    "        # device_map='auto',\n",
    "        torch_dtype=compute_dtype,\n",
    "        quantization_config=bnb_config, \n",
    "    )\n",
    "    model.config.use_cache = False\n",
    "    model.config.pretraining_tp = 1\n",
    "\n",
    "    # Tải tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path, max_seq_length=max_seq_length)\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # Kết thúc tính thời gian\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    print(f\"Execution time: {execution_time:.2f} seconds\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# Sử dụng hàm\n",
    "# Sử dụng hàm cho các mô hình khác nhau\n",
    "model_name_gemma_2 = \"E:\\\\gemma\\\\trained_weigths_2b\"\n",
    "model_name_gemma_7 = \"E:\\\\gemma\\\\trained_weigths\"\n",
    "model_name_llama3_8 = \"E:\\\\llama\\\\trained_weigths\"  # Đường dẫn cho mô hình llama8\n",
    "model_name_phi3 = \"E:\\\\phi3\"  # Đường dẫn cho mô hình phi3\n",
    "\n",
    "model_gemma_7, tokenizer_gemma_7 = load_model_and_tokenizer(model_name_gemma_7)\n",
    "model_gemma_2, tokenizer_gemma_2 = load_model_and_tokenizer(model_name_gemma_2)\n",
    "model_llama3_8, tokenizer_llama3_8 = load_model_and_tokenizer(model_name_llama3_8)\n",
    "# phi3_model, tokenizer_phi3 = load_model_and_tokenizer(model_name_phi3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af34e8e8",
   "metadata": {},
   "source": [
    "## test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15221677",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1= \"According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c9cc2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for model_gemma_2: ['neutral']\n",
      "Predictions for model_gemma_7: ['neutral']\n",
      "Predictions for model_llama3_8: ['neutral']\n"
     ]
    }
   ],
   "source": [
    "# Sử dụng hàm predict cho các mô hình khác nhau\n",
    "y_pred_gemma_2 = predict(X_test1, model_gemma_2, tokenizer_gemma_2)\n",
    "y_pred_gemma_7 = predict(X_test1, model_gemma_7, tokenizer_gemma_7)\n",
    "y_pred_llama3_8 = predict(X_test1, model_llama3_8, tokenizer_llama3_8)\n",
    "# y_pred_phi3 = predict(X_test1, phi3_model, tokenizer_phi3)\n",
    "\n",
    "# In kết quả dự đoán\n",
    "print(\"Predictions for model_gemma_2:\", y_pred_gemma_2)\n",
    "print(\"Predictions for model_gemma_7:\", y_pred_gemma_7)\n",
    "print(\"Predictions for model_llama3_8:\", y_pred_llama3_8)\n",
    "# print(\"Predictions for model_phi3:\", y_pred_phi3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abae7f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc949c03",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2b2e10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "\n",
    "def run_predictions():\n",
    "    input_data = input_text.get(\"1.0\", tk.END).strip()  # Get multi-line input\n",
    "    \n",
    "    if not input_data:\n",
    "        output_text.delete(1.0, tk.END)\n",
    "        output_text.insert(tk.END, \"Please enter some input data.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        X_test1 = [input_data]\n",
    "        y_pred_gemma_2 = predict(X_test1, model_gemma_2, tokenizer_gemma_2)\n",
    "        y_pred_gemma_7 = predict(X_test1, model_gemma_7, tokenizer_gemma_7)\n",
    "        y_pred_llama3_8 = predict(X_test1, model_llama3_8, tokenizer_llama3_8)\n",
    "\n",
    "        results = (\n",
    "            f\"Predictions for model_gemma_2: {y_pred_gemma_2}\\n\"\n",
    "            f\"Predictions for model_gemma_7: {y_pred_gemma_7}\\n\"\n",
    "            f\"Predictions for model_llama3_8: {y_pred_llama3_8}\\n\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        results = f\"An error occurred: {str(e)}\"\n",
    "    \n",
    "    output_text.delete(1.0, tk.END)\n",
    "    output_text.insert(tk.END, results)\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Model Prediction GUI\")\n",
    "\n",
    "# Create the interface\n",
    "tk.Label(root, text=\"Enter input data:\").pack(pady=10)\n",
    "\n",
    "# Use a Text widget for larger input area\n",
    "input_text = tk.Text(root, height=5, width=60)  # Increase height and width\n",
    "input_text.pack(pady=10)\n",
    "\n",
    "predict_button = tk.Button(root, text=\"Run Predictions\", command=run_predictions)\n",
    "predict_button.pack(pady=20)\n",
    "\n",
    "# Text widget to display results\n",
    "output_text = tk.Text(root, height=10, width=60)\n",
    "output_text.pack(pady=10)\n",
    "\n",
    "# Start the main loop of the GUI\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 622510,
     "sourceId": 1192499,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "llama3_212",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6838.673758,
   "end_time": "2024-06-20T23:19:12.346812",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-20T21:25:13.673054",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00d8d3148d174c20b5e91b8147fdbcd4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b899350b67349b2b940186b84946a53": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_37c18815c6664d2eab7b5cb3a8c993bc",
        "IPY_MODEL_8496dd2d1c3642b0b31e63b3091c65ea",
        "IPY_MODEL_9d820edaebd24601bfa027c079c12155"
       ],
       "layout": "IPY_MODEL_00d8d3148d174c20b5e91b8147fdbcd4"
      }
     },
     "29015cb862314aa1b112c42770e1c3e2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2b875d46b3d344b9bee90938d70f331c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d5cc86756e2478fb361507e7f07a4e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2f5ba648f1ff49e3ab198f0852e72891": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_988c04b443e74e5bbe9222a44ba51775",
       "max": 900,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d811750bf1144d10b824b893b2ea260d",
       "value": 900
      }
     },
     "2f74bc32c08842a8b0b4009b52a79512": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "346509a3d92948aeb5c0ac773dfb42b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37c18815c6664d2eab7b5cb3a8c993bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_29015cb862314aa1b112c42770e1c3e2",
       "placeholder": "​",
       "style": "IPY_MODEL_a315751b5d13489dbef67d7006b104b7",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "57c5ffa894a74a8faaed08fc88d4d2ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5bbec511bbae4591995c7a78e6b0c80b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_346509a3d92948aeb5c0ac773dfb42b9",
       "placeholder": "​",
       "style": "IPY_MODEL_8c82fee8112a4c38a4d4b37a641a7831",
       "value": " 900/900 [00:00&lt;00:00, 4069.54 examples/s]"
      }
     },
     "5f064603cb9a4b5a9d674bf08c3824bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c5e0e10bafb640b68962698a4cbb5638",
       "placeholder": "​",
       "style": "IPY_MODEL_2d5cc86756e2478fb361507e7f07a4e3",
       "value": "Map: 100%"
      }
     },
     "7743078c7fc743ae9dd7d5217aefb511": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8496dd2d1c3642b0b31e63b3091c65ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7743078c7fc743ae9dd7d5217aefb511",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cbe68a0487f54bbdbdcaae752d2545e2",
       "value": 4
      }
     },
     "8b562ece5ce246859b435c3b0955f815": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5f064603cb9a4b5a9d674bf08c3824bb",
        "IPY_MODEL_2f5ba648f1ff49e3ab198f0852e72891",
        "IPY_MODEL_5bbec511bbae4591995c7a78e6b0c80b"
       ],
       "layout": "IPY_MODEL_2b875d46b3d344b9bee90938d70f331c"
      }
     },
     "8c82fee8112a4c38a4d4b37a641a7831": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "988c04b443e74e5bbe9222a44ba51775": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9d820edaebd24601bfa027c079c12155": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2f74bc32c08842a8b0b4009b52a79512",
       "placeholder": "​",
       "style": "IPY_MODEL_57c5ffa894a74a8faaed08fc88d4d2ec",
       "value": " 4/4 [01:46&lt;00:00, 22.84s/it]"
      }
     },
     "a315751b5d13489dbef67d7006b104b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c5e0e10bafb640b68962698a4cbb5638": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cbe68a0487f54bbdbdcaae752d2545e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d811750bf1144d10b824b893b2ea260d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
